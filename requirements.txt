#
# This file is autogenerated by pip-compile with Python 3.10
# by the following command:
#
#    pip-compile
#
accelerate==0.23.0
    # via
    #   peft
    #   trl
aiohttp==3.8.6
    # via
    #   datasets
    #   fsspec
aiosignal==1.3.1
    # via aiohttp
appdirs==1.4.4
    # via wandb
async-timeout==4.0.3
    # via aiohttp
attrs==23.1.0
    # via aiohttp
certifi==2023.7.22
    # via
    #   requests
    #   sentry-sdk
charset-normalizer==3.3.0
    # via
    #   aiohttp
    #   requests
click==8.1.7
    # via wandb
datasets==2.14.5
    # via trl
deepspeed==0.11.1
    # via -r requirements.in
dill==0.3.7
    # via
    #   datasets
    #   multiprocess
docker-pycreds==0.4.0
    # via wandb
docstring-parser==0.15
    # via tyro
filelock==3.12.4
    # via
    #   huggingface-hub
    #   torch
    #   transformers
    #   triton
frozenlist==1.4.0
    # via
    #   aiohttp
    #   aiosignal
fsspec[http]==2023.6.0
    # via
    #   datasets
    #   huggingface-hub
    #   torch
gitdb==4.0.10
    # via gitpython
gitpython==3.1.37
    # via wandb
hjson==3.1.0
    # via deepspeed
huggingface-hub==0.17.3
    # via
    #   accelerate
    #   datasets
    #   tokenizers
    #   transformers
idna==3.4
    # via
    #   requests
    #   yarl
jinja2==3.1.2
    # via torch
markdown-it-py==3.0.0
    # via rich
markupsafe==2.1.3
    # via jinja2
mdurl==0.1.2
    # via markdown-it-py
mpmath==1.3.0
    # via sympy
multidict==6.0.4
    # via
    #   aiohttp
    #   yarl
multiprocess==0.70.15
    # via datasets
networkx==3.1
    # via torch
ninja==1.11.1.1
    # via deepspeed
numpy==1.26.1
    # via
    #   accelerate
    #   datasets
    #   deepspeed
    #   pandas
    #   peft
    #   pyarrow
    #   transformers
    #   trl
nvidia-cublas-cu12==12.1.3.1
    # via
    #   nvidia-cudnn-cu12
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cuda-cupti-cu12==12.1.105
    # via torch
nvidia-cuda-nvrtc-cu12==12.1.105
    # via torch
nvidia-cuda-runtime-cu12==12.1.105
    # via torch
nvidia-cudnn-cu12==8.9.2.26
    # via torch
nvidia-cufft-cu12==11.0.2.54
    # via torch
nvidia-curand-cu12==10.3.2.106
    # via torch
nvidia-cusolver-cu12==11.4.5.107
    # via torch
nvidia-cusparse-cu12==12.1.0.106
    # via
    #   nvidia-cusolver-cu12
    #   torch
nvidia-nccl-cu12==2.18.1
    # via torch
nvidia-nvjitlink-cu12==12.2.140
    # via
    #   nvidia-cusolver-cu12
    #   nvidia-cusparse-cu12
nvidia-nvtx-cu12==12.1.105
    # via torch
packaging==23.2
    # via
    #   accelerate
    #   datasets
    #   deepspeed
    #   huggingface-hub
    #   peft
    #   transformers
pandas==2.1.1
    # via datasets
pathtools==0.1.2
    # via wandb
peft==0.5.0
    # via -r requirements.in
protobuf==4.24.4
    # via wandb
psutil==5.9.6
    # via
    #   accelerate
    #   deepspeed
    #   peft
    #   wandb
py-cpuinfo==9.0.0
    # via deepspeed
pyarrow==13.0.0
    # via datasets
pydantic==1.10.13
    # via deepspeed
pygments==2.16.1
    # via rich
python-dateutil==2.8.2
    # via pandas
pytz==2023.3.post1
    # via pandas
pyyaml==6.0.1
    # via
    #   accelerate
    #   datasets
    #   huggingface-hub
    #   peft
    #   transformers
    #   wandb
regex==2023.10.3
    # via transformers
requests==2.31.0
    # via
    #   datasets
    #   fsspec
    #   huggingface-hub
    #   transformers
    #   wandb
rich==13.6.0
    # via tyro
safetensors==0.4.0
    # via
    #   peft
    #   transformers
sentencepiece==0.1.99
    # via -r requirements.in
sentry-sdk==1.32.0
    # via wandb
setproctitle==1.3.3
    # via wandb
shtab==1.6.4
    # via tyro
six==1.16.0
    # via
    #   docker-pycreds
    #   python-dateutil
smmap==5.0.1
    # via gitdb
sympy==1.12
    # via torch
tokenizers==0.14.1
    # via
    #   -r requirements.in
    #   transformers
torch==2.1.0
    # via
    #   -r requirements.in
    #   accelerate
    #   deepspeed
    #   peft
    #   trl
tqdm==4.66.1
    # via
    #   datasets
    #   deepspeed
    #   huggingface-hub
    #   peft
    #   transformers
transformers==4.34.0
    # via
    #   -r requirements.in
    #   peft
    #   trl
triton==2.1.0
    # via torch
trl==0.7.2
    # via -r requirements.in
typing-extensions==4.8.0
    # via
    #   huggingface-hub
    #   pydantic
    #   torch
    #   tyro
tyro==0.5.10
    # via trl
tzdata==2023.3
    # via pandas
urllib3==2.0.6
    # via
    #   requests
    #   sentry-sdk
wandb==0.15.12
    # via -r requirements.in
xxhash==3.4.1
    # via datasets
yarl==1.9.2
    # via aiohttp

# The following packages are considered to be unsafe in a requirements file:
# setuptools
